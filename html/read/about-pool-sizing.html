<!DOCTYPE html>
<html lang="zh-CN">
<head>
	<base href="../../">
	<meta charset="utf8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
	<link rel="shortcut icon" href="img/pb16x16.ico" title="B_Pt">
	<link rel="stylesheet" type="text/css" href="js/bootstrap-3.3.7-dist/css/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="js/bootstrap-3.3.7-dist/css/bootstrap-theme.min.css">
	<link rel="stylesheet" type="text/css" href="js/syntaxhighlighter/theme.css">
	<link rel="stylesheet" type="text/css" href="css/common.css">
	<title>å…³äºæ•°æ®åº“è¿æ¥æ± å¤§å°</title>
	<style>
		.en{
			margin: 10px;
			font-style: italic;
		}
		.cn {
			margin: 10px;
			color: #985F0D;
			font-size: 16px;
		}
		.licn{
			color: #985F0D;
			font-size: 16px;
		}
		.formula {
			size: 16px;
			font-weight: bolder;
		}
		hr {
			height:1px;
			border:none;
			border-top:1px solid #555555
		}
		h4{
			font-weight: bolder;
		}
	</style>
</head>
<body>
	<!-- navitor -->
	<div class="">
		<nav class="navbar navbar-default navbar-static-top">
			<div class="container-fluid">
				<button type="button" class="btn btn-default navbar-btn navbar-right">Home</button>
			</div>
		</nav>
	</div>
	<div class="container-fluid">
		<div id="catalog" class="col-lg-2"></div>
		<div class="col-lg-8">
			<div class="container-fluid">
				<ol class="breadcrumb">
					<li><a href="mainpage.html">Home</a></li>
					<li><a href="#">Read</a></li>
					<li class="active">Article</li>
				</ol>
			</div>
			<div class="container">
				<div class="page-header">
					<h3>å…³äºæ•°æ®åº“è¿æ¥æ± å¤§å°</h3>
					<small>2019-03-30</small>
				</div>
				<p>åŸæ–‡åœ°å€:<a href="https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing">About Pool Sizing</a></p>
				<div class="bg-gray">
					<em>
						GITHUB brettwooldridge/HikariCP WIKI
					</em>
				</div>
				<div class="centent">
					<div class="en">Configuring a connection pool is something that developers often get wrong. There are several, possibly counter-intuitive for some, principles that need to be understood when configuring the pool.</div>
					<div class="cn">é…ç½®è¿æ¥æ± æ˜¯å¼€å‘è€…ç»å¸¸å‡ºé”™è¯¯çš„åœ°æ–¹ã€‚è¿™é‡Œæœ‰å‡ ä¸ªåœ¨é…ç½®è¿æ¥æ± æ—¶éœ€è¦äº†è§£çš„ï¼Œå¯èƒ½æ˜¯åç›´è§‰çš„åŸåˆ™</div>
					<hr>
					<h4>10,000 Simultaneous Front-End Users</h4>
					<h4>10,000ä¸ªå‰ç«¯ç”¨æˆ·åŒæ—¶è®¿é—®</h4>
					<div class="en">Imagine that you have a website that while maybe not Facebook-scale still often has 10,000 users making database requests simultaneously -- accounting for some 20,000 transactions per second. How big should your connection pool be? You might be surprised that the question is not <i>how big</i> but rather <i>how small</i></div>
					<div class="cn">å‡å¦‚ä½ æœ‰ä¸€ä¸ªç½‘ç«™ï¼Œè™½ç„¶æ²¡æœ‰Facebooké‚£æ ·çš„è§„æ¨¡ï¼Œä½†ä»ç„¶æœ‰10,000ä¸ªç”¨æˆ·åœ¨åŒæ—¶è®¿é—®æ•°æ®åº“-- æ¯ç§’éœ€è¦20,000ä¸ªæ•°æ®åº“äº‹åŠ¡ã€‚ä½ çš„æ•°æ®åº“è¿æ¥æ± åº”è¯¥æ˜¯å¤šå¤§ï¼Ÿæ‚¨å¯èƒ½ä¼šæ„Ÿåˆ°æƒŠè®¶çš„æ˜¯ï¼Œä¸å…¶é—®è¿æ¥æ± <strong><i>è¯¥é…ç½®å¤šå¤§</strong></i>å€’ä¸å¦‚é—®<strong><i>è¯¥é…ç½®å¤šå°</i></strong>ï¼</div>
					<br/>
					<div class="en">Watch this short video from the Oracle Real-World Performance group for an eye-opening demonstration (~10 min.):</div>
					<div class="cn">è§‚çœ‹æ¥è‡ªOracle Real-World Performanceç»„çš„çš„è¿™æ®µè®©äººå¤§å¼€çœ¼ç•Œçš„ç®€çŸ­æ¼”ç¤ºè§†é¢‘ï¼ˆçº¦10åˆ†é’Ÿï¼‰ï¼š</div>
					<div style="text-align: center;"><a href="https://www.dailymotion.com/video/x2s8uec">OLTP Performance - Concurrent Mid-Tier Connections</a></div>
					<br/>
					<div class="en">{Spoiler Alert} if you didn't watch the video. Oh come on! Watch it then come back here.</div>
					<div class="cn">{å‰§é€è­¦å‘Š} å¦‚æœä½ æ²¡æœ‰çœ‹è¿™ä¸ªè§†é¢‘ï¼Œ å°ä¼™å­ï¼Œçœ‹å®Œå†å›æ¥ã€‚</div>
					
					<div class="en">You can see from the video that reducing the connection pool size alone, in the absence of any other change, decreased the response times of the application from ~100ms to ~2ms -- over 50x improvement.</div>
					<div class="cn">ä»è§†é¢‘æ€»å¯ä»¥çœ‹å‡ºï¼Œå•å•å‡å°‘è¿æ¥æ± çš„å¤§å°ï¼Œä¸ç”¨åšå…¶ä»–æ”¹å˜ï¼Œä½¿åº”ç”¨çš„å“åº”æ—¶é—´ä» ~100ms é™ä½åˆ°äº† ~2ms --è¶…è¿‡50è¢«çš„æå‡</div>
					
					<br />
					<h4>But why?</h4>
					<h4>åŸå› æ˜¯ä»€ä¹ˆ</h4>
					<br />
					<div class="en">We seem to have understood in other parts of computing recently that less is more. Why is it that with only 4-threads an nginx web-server can substantially out-perform an Apache web-server with 100 processes? Isn't it obvious if you think back to Computer Science 101?</div>
					
					<div class="cn">æˆ‘ä»¬å¥½åƒå¯ä»¥ä»å…¶ä»–è®¡ç®—åœºæ™¯ä¸­å»ç†è§£ä¸ºä»€ä¹ˆè¶Šå°‘è¶Šå¥½ã€‚ä¸ºä»€ä¹ˆåªæœ‰4ä¸ªçº¿ç¨‹çš„nginx WebæœåŠ¡å™¨å¯ä»¥å¤§å¤§è¶…è¿‡100ä¸ªè¿›ç¨‹çš„Apache WebæœåŠ¡å™¨ï¼Ÿå¦‚æœä½ å›æƒ³ä¸€ä¸‹Computer Science 101ï¼Œè¿™ä¸æ˜¯å¾ˆæ˜æ˜¾å—ï¼Ÿ</div>
					
					<div class="en">Even a computer with one CPU core can "simultaneously" support dozens or hundreds of threads. But we all [should] know that this is merely a trick by the operating system though the magic of time-slicing. In reality, that single core can only execute one thread at a time; then the OS switches contexts and that core executes code for another thread, and so on. It is a basic Law of Computing that given a single CPU resource, executing A and B sequentially will <i>always</i> be faster than executing A and B "simultaneously" through time-slicing. Once the number of threads exceeds the number of CPU cores, you're going slower by adding more threads, not faster.</div>
					<div class="cn">å³ä½¿æ˜¯å…·æœ‰ä¸€ä¸ªCPUå†…æ ¸çš„è®¡ç®—æœºä¹Ÿå¯ä»¥â€œåŒæ—¶â€æ”¯æŒæ•°åä¸ªæˆ–æ•°ç™¾ä¸ªçº¿ç¨‹ã€‚ä½†æ˜¯æˆ‘ä»¬éƒ½ã€åº”è¯¥ã€‘çŸ¥é“è¿™åªæ˜¯æ“ä½œç³»ç»Ÿä½¿ç”¨<i>æ—¶é—´ç‰‡</i>çš„ä¸€ä¸ªæŠ€å·§.å®é™…ä¸Šï¼Œå•ä¸ªæ ¸å¿ƒä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªçº¿ç¨‹; ç„¶åOSé€šè¿‡åˆ‡æ¢ä¸Šä¸‹æ–‡ï¼Œå»æ‰§è¡Œå¦ä¸€ä¸ªçº¿ç¨‹ä»£ç ï¼Œä¾æ­¤ç±»æ¨ã€‚ä¸€ä¸ªåŸºæœ¬çš„è®¡ç®—æ³•åˆ™æ˜¯ï¼Œç»™å®šèµ„æºçš„å•ä¸ªCPUï¼Œ é¡ºåºæ‰§è¡ŒAå’ŒB <i>æ€»æ˜¯</i>æ¯”é€šè¿‡æ—¶é—´ç‰‡åˆ‡æ¢â€œåŒæ—¶â€ æ‰§è¡ŒAå’ŒBæ›´å¿«ã€‚ä¸€æ—¦çº¿ç¨‹æ•°è¶…è¿‡äº†CPUæ ¸å¿ƒæ•°ï¼Œæ·»åŠ æ›´å¤šçº¿ç¨‹å°±ä¼šå˜å¾—æ›´æ…¢ï¼Œè€Œä¸æ˜¯æ›´å¿«ã€‚</div>
					<div class="en">That is almost true...</div>
					<div class="cn">è¿™<i>å‡ ä¹</i>æ˜¯çœŸçš„......</div>
					<br />
					<h4>Limited Resources</h4>
					<h4>æœ‰é™çš„èµ„æº</h4>
					<br />
					
					<div class="en">It is not quite as simple as stated above, but it's close. There are a few other factors at play. When we look at what the major bottlenecks for a database are, they can be summarized as three basic categories: CPU, Disk, Network. We could add Memory in there, but compared to Disk and Network there are several orders of magnitude difference in bandwidth.</div>
					<div class="cn">è™½ç„¶å®ƒå¹¶ä¸åƒä¸Šé¢è¯´çš„é‚£ä¹ˆç®€å•ï¼Œä½†å®ƒå¾ˆæ¥è¿‘ã€‚è¿˜æœ‰ä¸€äº›å…¶ä»–å› ç´ åœ¨èµ·ä½œç”¨ã€‚å½“æˆ‘ä»¬æŸ¥çœ‹æ•°æ®åº“çš„ä¸»è¦ç“¶é¢ˆæ˜¯ä»€ä¹ˆæ—¶ï¼Œå®ƒä»¬å¯ä»¥å½’çº³ä¸ºä¸‰ä¸ªåŸºæœ¬ç±»åˆ«ï¼šCPUï¼Œç£ç›˜ï¼Œç½‘ç»œã€‚æˆ‘ä»¬å¯ä»¥æ·»åŠ å†…å­˜æ”¹å–„çŠ¶å†µï¼Œä½†ä¸å†…å­˜ç›¸æ¯”ï¼Œç£ç›˜å’Œç½‘ç»œä¸å†…å­˜å¸¦å®½æœ‰å‡ ä¸ªæ•°é‡çº§çš„å·®å¼‚ã€‚</div>
					<div class="en">If we ignored Disk and Network it would be simple. On a server with 8 computing cores, setting the number of connections to 8 would provide optimal performance, and anything beyond this would start slowing down due to the overhead of context switching. But we cannot ignore Disk and Network. Databases typically store data on a Disk, which traditionally is comprised of spinning plates of metal with read/write heads mounted on a stepper-motor driven arm. The read/write heads can only be in one place at a time (reading/writing data for a single query) and must "seek" to a new location to read/write data for a different query. So there is a seek-time cost, and also a rotational cost whereby the disk has to wait for the data to "come around again" on the platter to be read/written. Caching of course helps here, but the principle still applies.</div>
					<div class="cn">å¦‚æœæˆ‘ä»¬å¿½ç•¥äº†ç£ç›˜å’Œç½‘ç»œï¼Œé‚£å°†å¾ˆç®€å•ã€‚åœ¨å…·æœ‰8ä¸ªè®¡ç®—æ ¸å¿ƒçš„æœåŠ¡å™¨ä¸Šï¼Œå°†è¿æ¥æ•°è®¾ç½®ä¸º8å°†æä¾›æœ€ä½³æ€§èƒ½ï¼Œå¹¶ä¸”ç”±äºä¸Šä¸‹æ–‡åˆ‡æ¢çš„å¼€é”€ï¼Œè¶…å‡ºæ­¤æ•°çš„é…ç½®éƒ½ä¼šä½¿CPUè®¡ç®—å‡æ…¢ã€‚ä½†æˆ‘ä»¬ä¸èƒ½å¿½è§†ç£ç›˜å’Œç½‘ç»œã€‚æ•°æ®åº“é€šå¸¸å°†æ•°æ®å­˜å‚¨åœ¨ç”±é‡‘å±æ—‹è½¬æ¿ç»„æˆï¼Œè¯»/å†™å¤´å®‰è£…åœ¨æ­¥è¿›ç”µæœºé©±åŠ¨è‡‚çš„ä¼ ç»Ÿç£ç›˜ä¸Šï¼Œè¯»/å†™ç£å¤´ä¸€æ¬¡åªèƒ½åœ¨ä¸€ä¸ªåœ°æ–¹ï¼ˆè¯»/å†™å•ä¸ªæŸ¥è¯¢çš„æ•°æ®ï¼‰ï¼Œå¹¶ä¸”å¿…é¡»â€œå¯»æ‰¾â€åˆ°æ–°ä½ç½®ä»¥è¯»å–/å†™å…¥ä¸åŒæŸ¥è¯¢çš„æ•°æ®ã€‚å› æ­¤å­˜åœ¨å¯»é“æ—¶é—´æˆæœ¬ï¼Œä»¥åŠæ—‹è½¬æˆæœ¬ï¼Œå…¶ä¸­ç£ç›˜å¿…é¡»ç­‰å¾…æ•°æ®åœ¨ç›˜ç‰‡ä¸Šâ€œå†æ¬¡å‡ºç°â€ä»¥è¿›è¡Œè¯»/å†™ã€‚ç¼“å­˜å½“ç„¶æœ‰å¸®åŠ©ï¼Œä½†åŸåˆ™ä»ç„¶é€‚ç”¨ã€‚</div>
					<div class="en">During this time ("I/O wait"), the connection/query/thread is simply "blocked" waiting for the disk. And it is during this time that the OS could put that CPU resource to better use by executing some more code for another thread. So, because threads become blocked on I/O, we can actually get more work done by having a number of connections/threads that is greater than the number of physical computing cores.</div>
					<div class="cn">åœ¨æ­¤æœŸé—´ï¼ˆâ€œI/Oç­‰å¾…â€ï¼‰ï¼Œè¿æ¥/æŸ¥è¯¢/çº¿ç¨‹è¢«â€œé˜»å¡â€ç­‰å¾…ç£ç›˜ã€‚åœ¨æ­¤æœŸé—´ï¼Œæ“ä½œç³»ç»Ÿå¯ä»¥é€šè¿‡ä¸ºå¦ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œæ›´å¤šä»£ç æ¥æ›´å¥½åœ°åˆ©ç”¨CPUèµ„æºã€‚å› æ­¤ï¼Œç”±äºçº¿ç¨‹åœ¨I/Oä¸Šè¢«é˜»å¡ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥é€šè¿‡ä½¿è¿æ¥/çº¿ç¨‹å¤§äºç‰©ç†è®¡ç®—æ ¸å¿ƒæ•°æ¥å®Œæˆæ›´å¤šå·¥ä½œã€‚</div>
					<div class="en">How many more? We shall see. The question of how many more also depends on the disk subsystem, because newer SSD drives do not have a "seek time" cost or rotational factors to deal with. Don't be tricked into thinking, "SSDs are faster and therefore I can have more threads". That is exactly 180 degrees backwards. Faster, no seeks, no rotational delays means less blocking and therefore fewer threads [closer to core count] will perform better than more threads. More threads only perform better when blocking creates opportunities for executing.</div>
					<div class="cn">æ›´å¤šæ˜¯å¤šå°‘ï¼Ÿæˆ‘ä»¬çŸ¥é“ï¼Œè¿™ä¸ªé—®é¢˜è¿˜å–å†³äºç£ç›˜å­ç³»ç»Ÿï¼Œå› ä¸ºè¾ƒæ–°çš„SSDé©±åŠ¨å™¨æ²¡æœ‰å¤„ç†â€œå¯»é“æ—¶é—´â€æˆæœ¬æˆ–æ—‹è½¬å› ç´ ã€‚ä¸è¦è¯¯ä»¥ä¸ºâ€œSSD é€Ÿåº¦æ›´å¿«ï¼Œå› æ­¤æˆ‘å¯ä»¥æ‹¥æœ‰æ›´å¤šçº¿ç¨‹â€ã€‚é‚£æ°æ°ç›¸åã€‚æ›´å¿«ï¼Œæ²¡æœ‰æœç´¢ï¼Œæ²¡æœ‰æ—‹è½¬å»¶è¿Ÿæ„å‘³ç€æ›´å°‘çš„é˜»å¡ï¼Œå› æ­¤æ›´å°‘çš„çº¿ç¨‹[æ›´æ¥è¿‘æ ¸å¿ƒæ•°é‡]å°†æ¯”æ›´å¤šçº¿ç¨‹æ›´å¥½åœ°æ‰§è¡Œã€‚ å½“é˜»å¡åˆ›å»ºæ‰§è¡Œæœºä¼šæ—¶ï¼Œæ›´å¤šçº¿ç¨‹æ‰æ‰§è¡Œå¾—æ›´å¥½ã€‚</div>
					<div class="en">Network is similar to disk. Writing data out over the wire, through the ethernet interface, can also introduce blocking when the send/receive buffers fill up and stall. A 10-Gig interface is going to stall less than Gigabit ethernet, which will stall less than a 100-megabit. But network is a 3rd place runner in terms of resource blocking and some people often omit it from their calculations.</div>
					<div class="cn">ç½‘ç»œç±»ä¼¼äºç£ç›˜ã€‚é€šè¿‡ä»¥å¤ªç½‘æ¥å£é€šè¿‡çº¿è·¯å†™å‡ºæ•°æ®ä¹Ÿä¼šåœ¨å‘é€/æ¥æ”¶ç¼“å†²åŒºå¡«æ»¡å’Œåœæ­¢æ—¶å¼•èµ·é˜»å¡ã€‚ä¸€ä¸ª10-Gigæ¥å£é˜»å¡å°äºåƒå…†ä»¥å¤ªç½‘ï¼Œåƒå…†ç½‘æ¥å£é˜»å¡å°äºç™¾å…†ç½‘æ¥å£ã€‚ä½†å°±èµ„æºé˜»å¡è€Œè¨€ï¼Œç½‘ç»œæ’åç¬¬ä¸‰ï¼Œæœ‰äº›äººç»å¸¸åœ¨è®¡ç®—ä¸­å¿½ç•¥å®ƒã€‚</div>
					<div class="en">Here's another chart to break up the wall of text.</div>
					<div class="cn">è¿™æ˜¯ä¸€ä¸ªå›¾è¡¨ï¼Œæ¯”æ–‡å­—æ›´æœ‰è¯´æœåŠ›ã€‚</div>
					<div>
						<img style="width:640px" src="https://github.com/brettwooldridge/HikariCP/wiki/Postgres_Chart.png" />
					</div>
					
					<div class="en">You can see in the above PostgreSQL benchmark that TPS rates start to flatten out at around 50 connections. And in Oracle's video above they showed dropping the connections from 2048 down to just 96. We would say that even 96 is probably too high, unless you're looking at a 16 or 32-core box.</div>
					<div class="cn">æ‚¨å¯ä»¥åœ¨ä¸Šé¢çš„PostgreSQLåŸºå‡†æµ‹è¯•ä¸­çœ‹åˆ°ï¼ŒTPSé€Ÿç‡æ›²çº¿å¼€å§‹åœ¨å¤§çº¦50ä¸ªè¿æ¥å¤„å˜å¹³ã€‚åœ¨ä¸Šé¢çš„Oracleè§†é¢‘ä¸­ï¼Œä»–ä»¬æŠŠè¿æ¥ä»2048ä¸‹é™åˆ°96ä¸ª.æˆ‘ä»¬ä¼šè¯´å³ä½¿96ä¹Ÿå¯èƒ½å¤ªé«˜äº†ï¼Œé™¤éä½ æœ‰ä¸€ä¸ª16æˆ–32æ ¸çš„CPU</div>
					<br />
					<h4>The Formula</h4>
					<h4>å…¬å¼</h4>
					<br />
					
					<div class="en">The formula below is provided by the PostgreSQL project as a starting point, but we believe it will be largely applicable across databases. You should test your application, i.e. simulate expected load, and try different pool settings around this starting point:</div>
					<div class="cn">ä¸‹é¢çš„å…¬å¼ç”±PostgreSQLé¡¹ç›®æä¾›çš„ä¸€ä¸ªåŸºç¡€é…ç½®æ•°å€¼ï¼Œä½†æˆ‘ä»¬ç›¸ä¿¡å®ƒå°†åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šé€‚ç”¨äºæ‰€æœ‰æ•°æ®åº“ã€‚æ‚¨åº”è¯¥æµ‹è¯•æ‚¨çš„åº”ç”¨ç¨‹åºï¼Œæ¯”å¦‚æ¨¡æ‹Ÿé¢„æœŸçš„è´Ÿè½½ï¼Œå¹¶åœ¨æ­¤æ•°å€¼ä¸Šä¸‹å°è¯•ä¸åŒçš„æ± è®¾ç½®ï¼š</div>
					<div class="en">connections = ((core_count * 2) + effective_spindle_count)</div>
					<div class="cn"></div>
					<div class="en">A formula which has held up pretty well across a lot of benchmarks for years is that for optimal throughput the number of active connections should be somewhere near ((core_count * 2) + effective_spindle_count). Core count should not include HT threads, even if hyperthreading is enabled. Effective spindle count is zero if the active data set is fully cached, and approaches the actual number of spindles as the cache hit rate falls. ... There hasn't been any analysis so far regarding how well the formula works with SSDs.</div>
					<div class="cn">ä¸ºä¼˜åŒ–æ•°æ®åº“å¤šä¸ªè¿æ¥çš„ååé‡çš„è¿™ä¸ªå…¬å¼<strong>(cpuæ ¸å¿ƒæ•° * 2) + ç£ç›˜åˆ—é˜µä¸­çš„ç¡¬ç›˜æ•°</strong> å·²ç»è¢«è¿™å‡ å¹´æ¥çš„è®¸å¤šåŸºå‡†æµ‹è¯•æ‰€æ”¯æŒã€‚æ ¸å¿ƒæ•°ä¸åº”è¯¥åŒ…å«HT threadsï¼ˆè¶…çº¿ç¨‹ï¼‰ï¼Œå³ä½¿å¼€å¯äº†è¶…çº¿ç¨‹åŠŸèƒ½ã€‚å¦‚æœæ•°æ®é›†å·²å…¨éƒ¨è¢«ç¼“å­˜ï¼Œé‚£ä¹ˆEffective spindle count æ˜¯ 0ï¼Œå¹¶ä¸”æ¥è¿‘ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™æ—¶çš„å®é™…è½´æ•°ã€‚..åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¿˜æ²¡æœ‰ä»»ä½•å…³äºè¿™ä¸ªå…¬å¼åœ¨SSDç¡¬ç›˜æƒ…å†µä¸‹çš„åˆ†æ</div>
					<div class="en">Guess what that means? Your little 4-Core i7 server with one hard disk should be running a connection pool of: 9 = ((4 * 2) + 1). Call it 10 as a nice round number. Seem low? Give it a try, we'd wager that you could easily handle 3000 front-end users running simple queries at 6000 TPS on such a setup. If you run load tests, you will probably see TPS rates starting to fall, and front-end response times starting to climb, as you push the connection pool much past 10 (on that given hardware).</div>
					<div class="cn">çŒœçŒœé‚£æ„å‘³ç€ä»€ä¹ˆï¼Ÿä½ çš„å¸¦æœ‰ä¸€ä¸ªç¡¬ç›˜çš„å°å‹4æ ¸i7æœåŠ¡å™¨åº”è¿è¡Œä»¥ä¸‹è¿æ¥æ± ï¼š 9 = ((4 * 2) + 1)ã€‚10ä¸ªè¿æ¥å¯èƒ½æ˜¯ä¸ªä¸é”™çš„é…ç½®ï¼Œçœ‹èµ·æ¥å¾ˆå°‘ï¼Ÿè®©æˆ‘æ¥è¯•ä¸€ä¸‹ï¼Œåœ¨è¿™æ ·çš„è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬æ‰“èµŒæ‚¨å¯ä»¥è½»æ¾å¤„ç†3000ä¸ªå‰ç«¯ç”¨æˆ·ä»¥6000 TPSè¿›è¡Œç®€å•æŸ¥è¯¢ã€‚å¦‚æœæ‚¨è¿è¡Œè´Ÿè½½æµ‹è¯•ï¼Œå°†è¿æ¥æ± è¿æ¥æ•°é‡è®¾ç½®ä¸ºå¤§äº10ä¸ªï¼ˆåœ¨ç»™å®šç¡¬ä»¶ä¸Šï¼‰ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ°TPSé€Ÿç‡å¼€å§‹ä¸‹é™ï¼Œå¹¶ä¸”å‰ç«¯å“åº”æ—¶é—´å¼€å§‹æ”€å‡ã€‚</div>
					<br />
					<h4>Axiom: You want a small pool, saturated with threads waiting for connections.</h4>
					<h4>å®šç†ï¼šä½ æƒ³è¦ä¸€ä¸ªå°å‹æ± ï¼Œå’Œä¸€ä¸ªå……æ»¡äº†ç­‰å¾…è¿æ¥çš„çº¿ç¨‹çš„é˜Ÿåˆ—ã€‚</h4>
					<br />
					
					<div class="en">If you have 10,000 front-end users, having a connection pool of 10,000 would be shear insanity. 1000 still horrible. Even 100 connections, overkill. You want a small pool of a few dozen connections at most, and you want the rest of the application threads blocked on the pool awaiting connections. If the pool is properly tuned it is set right at the limit of the number of queries the database is capable of processing simultaneously -- which is rarely much more than (CPU cores * 2) as noted above.</div>
					<div class="cn">å¦‚æœæ‚¨æ‹¥æœ‰10,000ä¸ªå‰ç«¯ç”¨æˆ·ï¼Œæœ‰ä¸€ä¸ª10,000ä¸ªè¿æ¥çš„è¿æ¥æ± å°±å¤ªç–¯ç‹‚äº†ã€‚1000ä¸ªä»ç„¶å¯æ€•ã€‚å³ä½¿100ä¸ªè¿æ¥ï¼Œä¾ç„¶è®©äººå—ä¸äº†ã€‚æ‚¨æœ€å¤šéœ€è¦ä¸€ä¸ªåŒ…å«å‡ åä¸ªè¿æ¥çš„å°æ± ï¼Œç„¶åè®©å‰©ä¸‹çš„ä¸šåŠ¡çº¿ç¨‹éƒ½åœ¨é˜Ÿåˆ—é‡Œç­‰å¾…ã€‚å¦‚æœè¿æ¥æ± è¢«æ­£ç¡®è°ƒæ•´ï¼Œè¿æ¥æ± ä¸­çš„è¿æ¥æ•°é‡åº”è¯¥ç­‰äºä½ çš„æ•°æ®åº“èƒ½å¤Ÿæœ‰æ•ˆåŒæ—¶è¿›è¡Œçš„æŸ¥è¯¢ä»»åŠ¡æ•°ï¼ˆé€šå¸¸ä¸ä¼šé«˜äº2*CPUæ ¸å¿ƒæ•°ï¼‰ã€‚å¦‚ä¸Šæ‰€è¿°ã€‚</div>
					<div class="en">We never cease to amaze at the in-house web applications we've encountered, with a few dozen front-end users performing periodic activity, and a connection pool of 100 connections. Don't over-provision your database.</div>
					<div class="cn">æˆ‘ä»¬ç»å¸¸è§åˆ°ä¸€äº›å°è§„æ¨¡çš„webåº”ç”¨ï¼Œåº”ä»˜ç€å¤§çº¦åæ¥ä¸ªçš„å¹¶å‘ç”¨æˆ·ï¼Œå´ä½¿ç”¨ç€ä¸€ä¸ª100è¿æ¥æ•°çš„è¿æ¥æ± ã€‚è¿™ä¼šå¯¹ä½ çš„æ•°æ®åº“é€ æˆæå…¶ä¸å¿…è¦çš„è´Ÿæ‹…ã€‚</div>
					<hr />
					
					<br />
					<h4>"Pool-locking"</h4>
					<h4>â€œæ± é”â€</h4>
					<br />
					
					<div class="en">The prospect of "pool-locking" has been raised with respect to single actors that acquire many connections. This is largely an application-level issue. Yes, increasing the pool size can alleviate lockups in these scenarios, but we would urge you to examine first what can be done at the application level before enlarging the pool.</div>
					<div class="cn">â€œæ± é”â€é—®é¢˜åœ¨å•ä¸ªå‚ä¸è€…éœ€è¦å¤šä¸ªè¿æ¥çš„æƒ…å†µä¸‹è¢«æå‡ºã€‚è¿™ä¸»è¦æ˜¯åº”ç”¨ç¨‹åºçº§çš„é—®é¢˜ï¼Œæ˜¯çš„ï¼Œå¢åŠ æ± å¤§å°å¯ä»¥å‡è½»è¿™äº›æƒ…å†µä¸‹çš„é”å®šï¼Œä½†æˆ‘ä»¬å»ºè®®æ‚¨å…ˆæ£€æŸ¥åœ¨æ‰©å±•æ± ä¹‹å‰å¯ä»¥åœ¨åº”ç”¨ç¨‹åºçº§åˆ«æ‰§è¡Œçš„æ“ä½œã€‚</div>
					<div class="en">The calculation of pool size in order to avoid deadlock is a fairly simple resource allocation formula:</div>
					<div class="cn">ä¸ºé¿å…æ­»é”è€Œè®¡ç®—æ± å¤§å°æ˜¯ä¸€ä¸ªç›¸å½“ç®€å•çš„èµ„æºåˆ†é…å…¬å¼ï¼š</div>
					<div class="formula"> pool size = Tn x (Cm - 1) + 1</div>
					<div class="cn"></div>
					<div class="en">Where Tn is the maximum number of threads, and Cm is the maximum number of simultaneous connections held by a single thread.</div>
					<div class="cn">å…¶ä¸­Tnæ˜¯æœ€å¤§çº¿ç¨‹æ•°ï¼ŒCmæ˜¯å•ä¸ªçº¿ç¨‹æŒæœ‰çš„æœ€å¤§åŒæ—¶è¿æ¥æ•°ã€‚</div>
					<div class="en">For example, imagine three threads (Tn=3), each of which requires four connections to perform some task (Cm=4). The pool size required to ensure that deadlock is never possible is:</div>
					<div class="cn">ä¾‹å¦‚ï¼Œå‡å¦‚æœ‰ä¸‰ä¸ªçº¿ç¨‹ï¼ˆTn = 3ï¼‰ï¼Œæ¯ä¸ªçº¿ç¨‹éœ€è¦å››ä¸ªè¿æ¥æ¥æ‰§è¡ŒæŸäº›ä»»åŠ¡ï¼ˆCm = 4ï¼‰ã€‚ç¡®ä¿æ°¸è¿œä¸ä¼šå‡ºç°æ­»é”æ‰€éœ€çš„æ± å¤§å°æ˜¯ï¼š</div>
					<div class="formula"> pool size = 3 x (4 - 1) + 1 = 10</div>
					<div class="cn">å¦ä¸€ä¸ªä¾‹å­ï¼Œä½ æœ€å¤šæœ‰8ä¸ªçº¿ç¨‹ï¼ˆTn = 8ï¼‰ï¼Œæ¯ä¸ªçº¿ç¨‹éœ€è¦ä¸‰ä¸ªè¿æ¥æ‰èƒ½æ‰§è¡ŒæŸé¡¹ä»»åŠ¡ï¼ˆCm = 3ï¼‰ã€‚ç¡®ä¿æ°¸è¿œä¸ä¼šå‡ºç°æ­»é”æ‰€éœ€çš„æ± å¤§å°æ˜¯ï¼š</div>
					<div class="en">Another example, you have a maximum of eight threads (Tn=8), each of which requires three connections to perform some task (Cm=3). The pool size required to ensure that deadlock is never possible is:</div>
					<div class="cn"></div>
					<div class="formula">pool size = 8 x (3 - 1) + 1 = 17</div>
					<div class="cn"></div>
					
					<div class="en">ğŸ‘‰ This is not necessarily the optimal pool size, but the minimum required to avoid deadlock.</div>
					<div class="cn">ğŸ‘‰è¿™ä¸ä¸€å®šæ˜¯æœ€ä½³æ± å¤§å°ï¼Œè€Œæ˜¯é¿å…æ­»é”æ‰€éœ€çš„æœ€å°å€¼ã€‚</div>
					<div class="en">ğŸ‘‰ In some environments, using a JTA (Java Transaction Manager) can dramatically reduce the number of connections required by returning the same Connection from getConnection() to a thread that is already holding a Connection in the current transaction.</div>
					<div class="cn">ğŸ‘‰åœ¨æŸäº›ç¯å¢ƒä¸­ï¼Œä½¿ç”¨JTAï¼ˆJavaäº‹åŠ¡ç®¡ç†å™¨ï¼‰å¯ä»¥æ˜¾ç€å‡å°‘å°†åŒä¸€è¿æ¥è¿”å›getConnection()åˆ°å½“å‰äº‹åŠ¡ä¸­å·²æŒæœ‰Connectionçš„çº¿ç¨‹æ‰€éœ€çš„è¿æ¥æ•°ã€‚ğŸ‘‰</div>
					<hr />
					<br />
					<h4>Caveat Lector</h4>
					<h4></h4>
					<br />
					
					<div class="en">Pool sizing is ultimately very specific to deployments.</div>
					<div class="cn">è¿æ¥æ± çš„å¤§å°æœ€ç»ˆä¸ç³»ç»Ÿç‰¹æ€§ç›¸å…³ã€‚</div>
					<div class="en">For example, systems with a mix of long running transactions and very short transactions are generally the most difficult to tune with any connection pool. In those cases, creating two pool instances can work well (eg. one for long-running jobs, another for "realtime" queries).</div>
					<div class="cn">ä¾‹å¦‚ï¼Œæ··åˆäº†é•¿æ—¶é—´è¿è¡Œäº‹åŠ¡å’Œéå¸¸çŸ­äº‹åŠ¡çš„ç³»ç»Ÿé€šå¸¸æ˜¯æœ€éš¾è°ƒæ•´çš„ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œåˆ›å»ºä¸¤ä¸ªæ± å®ä¾‹å¯ä»¥å¾ˆå¥½åœ°å·¥ä½œï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªç”¨äºé•¿æ—¶é—´è¿è¡Œçš„ä½œä¸šï¼Œå¦ä¸€ä¸ªç”¨äºâ€œå®æ—¶â€æŸ¥è¯¢ï¼‰ã€‚</div>
					<div class="en">In systems with primarily long running transactions, there is often an "outside" constraint on the number of connections needed -- such as a job execution queue that only allows a certain number of jobs to run at once. In these cases, the job queue size should be "right-sized" to match the pool (rather than the other way around).</div>
					<div class="cn">åœ¨ä¸»è¦å…·æœ‰é•¿æ—¶é—´è¿è¡Œäº‹åŠ¡çš„ç³»ç»Ÿä¸­ï¼Œæ‰€éœ€çš„è¿æ¥æ•°é€šå¸¸å­˜åœ¨â€œå¤–éƒ¨â€çº¦æŸ - ä¾‹å¦‚ï¼Œåªå…è®¸ä¸€æ¬¡è¿è¡Œä¸€å®šæ•°é‡çš„ä½œä¸šçš„ä½œä¸šæ‰§è¡Œé˜Ÿåˆ—ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä½œä¸šé˜Ÿåˆ—å¤§å°åº”è¯¥æ˜¯â€œæ°å¥½â€åŒ¹é…æ± å¤§å°ï¼ˆè€Œä¸æ˜¯ç›¸åï¼‰ã€‚</div>
				</div>
			</div>
		</div>
	</div>
	<div class="container">
		<div class="footer text-center">
			<hr style="height:1px;border:none;border-top:1px solid #555555;" />
			<em>The world is so interesting</em>
		</div>
	</div>
	<script type="text/javascript" src="js/jquery-3.2.1.min.js"></script>
	<script type="text/javascript" src="js/bootstrap-3.3.7-dist/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="js/syntaxhighlighter/syntaxhighlighter.js"></script>
</body>
</html>
